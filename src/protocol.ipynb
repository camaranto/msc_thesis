{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afc8ec79",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# A cryptographic protocol to train classification models with federated learning and homomorphic encryption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16791611",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "854e0dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "from simulation.simulation import Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759f841f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Pickle Functions and Simulation Execution Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dcbb6832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_save(data, path, filename):\n",
    "    with open(os.path.join(path, filename), 'wb') as file:\n",
    "        pkl.dump(data, file)\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def pickle_load(path, filename):\n",
    "    with open(os.path.join(path, filename), 'rb') as file:\n",
    "        data = pkl.load(file)\n",
    "        return data\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66b3d56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = os.path.join(os.path.abspath(os.pardir), 'executions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaac8ab",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Load Data\n",
    "\n",
    "This notebook involves learning using images data from multiple clients to predict digits. The data is a standard dataset from sklearn [1].\n",
    "\n",
    "[1] https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a747a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_digits()\n",
    "\n",
    "X, y = dataset.data, dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb85b15a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Scenario 1\n",
    "\n",
    "This scenario uses a MLP Neural Network for classification with the following structure and information:\n",
    "- 64 features.\n",
    "- 10 classes.\n",
    "- No hidden layers.\n",
    "- Weights and biases initializated in zeros.\n",
    "- Softmax as output layer.\n",
    "\n",
    "The protocol runs over 5 clients and the key length of homomorphic cryptosystem is 1024 bits.\n",
    "\n",
    "The train is executed using 90% of data equally distributed over the 5 clients, with 0.01 as learning rate and 120 epochs.\n",
    "\n",
    "The test is executed using the remaining 10% of data for all clients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa450cfc",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "501efe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPERPARAMS_1 = {\n",
    "    'n_clients': 5,\n",
    "    'key_length': 1024,\n",
    "    'architecture': {\n",
    "        'n_features': 64, \n",
    "        'n_classes': 10,\n",
    "        'hidden_layers_size': (),\n",
    "        'activations': (),\n",
    "        'initialization': 'zeros'\n",
    "    },\n",
    "    'train': {\n",
    "        'learning_rate': 0.01,\n",
    "        'epochs': 120\n",
    "    },\n",
    "    'test': {\n",
    "        'test_size': 0.1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c75eb89",
   "metadata": {},
   "source": [
    "### Simulation Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d36a7c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulaci贸n para 5 clientes\n",
      "\n",
      "        ============================================================================================\n",
      "        Layers size: (64, 10)\n",
      "        ============================================================================================\n",
      "        Activations: ('softmax',)\n",
      "        ============================================================================================\n",
      "        Trainable parameters: 650\n",
      "        ============================================================================================\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "simulation_1 = Simulation(X, y, **HYPERPARAMS_1)\n",
    "print(simulation_1)\n",
    "simulation_1.print_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4efac3",
   "metadata": {},
   "source": [
    "### Run on Local Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22d41f91",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running local training for 120 epochs...\n",
      "\n",
      "Metrics that each client gets on Test Set by training only on own local data:\n",
      "\n",
      "|    | name     |   accuracy |    loss |   precision |   recall |   roc-auc |\n",
      "|---:|:---------|-----------:|--------:|------------:|---------:|----------:|\n",
      "|  0 | Client 1 |   0.916667 | 1.05915 |    0.926553 | 0.916667 |  0.993473 |\n",
      "|  1 | Client 2 |   0.872222 | 1.03494 |    0.887286 | 0.872222 |  0.992943 |\n",
      "|  2 | Client 3 |   0.883333 | 1.07236 |    0.914019 | 0.883333 |  0.992837 |\n",
      "|  3 | Client 4 |   0.9      | 1.05519 |    0.904683 | 0.9      |  0.992879 |\n",
      "|  4 | Client 5 |   0.9      | 1.04635 |    0.91044  | 0.9      |  0.993189 |\n"
     ]
    }
   ],
   "source": [
    "simulation_1.run_local()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b492a140",
   "metadata": {},
   "source": [
    "### Run the Federated Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8442de74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running distributed gradient aggregation for 120 epochs...\n",
      "\n",
      "- Epoch 001 / 120 : Epoch Time: 63.64s, Total Time: 63.64s\n",
      "- Epoch 002 / 120 : Epoch Time: 60.03s, Total Time: 123.68s\n",
      "- Epoch 003 / 120 : Epoch Time: 58.71s, Total Time: 182.39s\n",
      "- Epoch 004 / 120 : Epoch Time: 59.02s, Total Time: 241.41s\n",
      "- Epoch 005 / 120 : Epoch Time: 58.81s, Total Time: 300.21s\n",
      "- Epoch 006 / 120 : Epoch Time: 59.02s, Total Time: 359.23s\n",
      "- Epoch 007 / 120 : Epoch Time: 58.93s, Total Time: 418.16s\n",
      "- Epoch 008 / 120 : Epoch Time: 60.87s, Total Time: 479.03s\n",
      "- Epoch 009 / 120 : Epoch Time: 47.59s, Total Time: 526.62s\n",
      "- Epoch 010 / 120 : Epoch Time: 44.71s, Total Time: 571.33s\n",
      "- Epoch 011 / 120 : Epoch Time: 46.21s, Total Time: 617.54s\n",
      "- Epoch 012 / 120 : Epoch Time: 46.16s, Total Time: 663.70s\n",
      "- Epoch 013 / 120 : Epoch Time: 46.21s, Total Time: 709.92s\n",
      "- Epoch 014 / 120 : Epoch Time: 46.30s, Total Time: 756.22s\n",
      "- Epoch 015 / 120 : Epoch Time: 46.26s, Total Time: 802.47s\n",
      "- Epoch 016 / 120 : Epoch Time: 46.22s, Total Time: 848.69s\n",
      "- Epoch 017 / 120 : Epoch Time: 46.65s, Total Time: 895.34s\n",
      "- Epoch 018 / 120 : Epoch Time: 46.24s, Total Time: 941.59s\n",
      "- Epoch 019 / 120 : Epoch Time: 46.20s, Total Time: 987.79s\n",
      "- Epoch 020 / 120 : Epoch Time: 46.15s, Total Time: 1033.94s\n",
      "- Epoch 021 / 120 : Epoch Time: 46.29s, Total Time: 1080.22s\n",
      "- Epoch 022 / 120 : Epoch Time: 46.25s, Total Time: 1126.48s\n",
      "- Epoch 023 / 120 : Epoch Time: 46.28s, Total Time: 1172.76s\n",
      "- Epoch 024 / 120 : Epoch Time: 46.30s, Total Time: 1219.06s\n",
      "- Epoch 025 / 120 : Epoch Time: 46.25s, Total Time: 1265.31s\n",
      "- Epoch 026 / 120 : Epoch Time: 46.16s, Total Time: 1311.47s\n",
      "- Epoch 027 / 120 : Epoch Time: 46.27s, Total Time: 1357.74s\n",
      "- Epoch 028 / 120 : Epoch Time: 46.30s, Total Time: 1404.04s\n",
      "- Epoch 029 / 120 : Epoch Time: 46.22s, Total Time: 1450.26s\n",
      "- Epoch 030 / 120 : Epoch Time: 46.36s, Total Time: 1496.62s\n",
      "- Epoch 031 / 120 : Epoch Time: 46.25s, Total Time: 1542.87s\n",
      "- Epoch 032 / 120 : Epoch Time: 46.49s, Total Time: 1589.36s\n",
      "- Epoch 033 / 120 : Epoch Time: 46.29s, Total Time: 1635.65s\n",
      "- Epoch 034 / 120 : Epoch Time: 46.33s, Total Time: 1681.98s\n",
      "- Epoch 035 / 120 : Epoch Time: 46.37s, Total Time: 1728.35s\n",
      "- Epoch 036 / 120 : Epoch Time: 46.31s, Total Time: 1774.66s\n",
      "- Epoch 037 / 120 : Epoch Time: 46.38s, Total Time: 1821.04s\n",
      "- Epoch 038 / 120 : Epoch Time: 46.27s, Total Time: 1867.31s\n",
      "- Epoch 039 / 120 : Epoch Time: 46.99s, Total Time: 1914.29s\n",
      "- Epoch 040 / 120 : Epoch Time: 46.32s, Total Time: 1960.62s\n",
      "- Epoch 041 / 120 : Epoch Time: 46.35s, Total Time: 2006.96s\n",
      "- Epoch 042 / 120 : Epoch Time: 49.72s, Total Time: 2056.68s\n",
      "- Epoch 043 / 120 : Epoch Time: 48.90s, Total Time: 2105.58s\n",
      "- Epoch 044 / 120 : Epoch Time: 46.22s, Total Time: 2151.80s\n",
      "- Epoch 045 / 120 : Epoch Time: 46.27s, Total Time: 2198.06s\n",
      "- Epoch 046 / 120 : Epoch Time: 46.28s, Total Time: 2244.35s\n",
      "- Epoch 047 / 120 : Epoch Time: 46.24s, Total Time: 2290.59s\n",
      "- Epoch 048 / 120 : Epoch Time: 46.42s, Total Time: 2337.01s\n",
      "- Epoch 049 / 120 : Epoch Time: 46.38s, Total Time: 2383.39s\n",
      "- Epoch 050 / 120 : Epoch Time: 46.47s, Total Time: 2429.87s\n",
      "- Epoch 051 / 120 : Epoch Time: 46.52s, Total Time: 2476.38s\n",
      "- Epoch 052 / 120 : Epoch Time: 46.40s, Total Time: 2522.78s\n",
      "- Epoch 053 / 120 : Epoch Time: 46.56s, Total Time: 2569.34s\n",
      "- Epoch 054 / 120 : Epoch Time: 46.51s, Total Time: 2615.85s\n",
      "- Epoch 055 / 120 : Epoch Time: 46.49s, Total Time: 2662.34s\n",
      "- Epoch 056 / 120 : Epoch Time: 46.30s, Total Time: 2708.64s\n",
      "- Epoch 057 / 120 : Epoch Time: 46.34s, Total Time: 2754.98s\n",
      "- Epoch 058 / 120 : Epoch Time: 46.24s, Total Time: 2801.22s\n",
      "- Epoch 059 / 120 : Epoch Time: 46.32s, Total Time: 2847.54s\n",
      "- Epoch 060 / 120 : Epoch Time: 46.29s, Total Time: 2893.84s\n",
      "- Epoch 061 / 120 : Epoch Time: 46.20s, Total Time: 2940.03s\n",
      "- Epoch 062 / 120 : Epoch Time: 46.31s, Total Time: 2986.34s\n",
      "- Epoch 063 / 120 : Epoch Time: 46.27s, Total Time: 3032.61s\n",
      "- Epoch 064 / 120 : Epoch Time: 46.23s, Total Time: 3078.84s\n",
      "- Epoch 065 / 120 : Epoch Time: 46.16s, Total Time: 3125.00s\n",
      "- Epoch 066 / 120 : Epoch Time: 46.49s, Total Time: 3171.48s\n",
      "- Epoch 067 / 120 : Epoch Time: 46.29s, Total Time: 3217.78s\n",
      "- Epoch 068 / 120 : Epoch Time: 46.65s, Total Time: 3264.43s\n",
      "- Epoch 069 / 120 : Epoch Time: 48.52s, Total Time: 3312.95s\n",
      "- Epoch 070 / 120 : Epoch Time: 46.33s, Total Time: 3359.28s\n",
      "- Epoch 071 / 120 : Epoch Time: 46.83s, Total Time: 3406.11s\n",
      "- Epoch 072 / 120 : Epoch Time: 46.32s, Total Time: 3452.43s\n",
      "- Epoch 073 / 120 : Epoch Time: 46.43s, Total Time: 3498.86s\n",
      "- Epoch 074 / 120 : Epoch Time: 46.17s, Total Time: 3545.03s\n",
      "- Epoch 075 / 120 : Epoch Time: 46.45s, Total Time: 3591.48s\n",
      "- Epoch 076 / 120 : Epoch Time: 46.35s, Total Time: 3637.83s\n",
      "- Epoch 077 / 120 : Epoch Time: 46.43s, Total Time: 3684.27s\n",
      "- Epoch 078 / 120 : Epoch Time: 46.53s, Total Time: 3730.79s\n",
      "- Epoch 079 / 120 : Epoch Time: 46.30s, Total Time: 3777.09s\n",
      "- Epoch 080 / 120 : Epoch Time: 46.54s, Total Time: 3823.63s\n",
      "- Epoch 081 / 120 : Epoch Time: 46.35s, Total Time: 3869.98s\n",
      "- Epoch 082 / 120 : Epoch Time: 46.79s, Total Time: 3916.77s\n",
      "- Epoch 083 / 120 : Epoch Time: 46.35s, Total Time: 3963.12s\n",
      "- Epoch 084 / 120 : Epoch Time: 46.51s, Total Time: 4009.63s\n",
      "- Epoch 085 / 120 : Epoch Time: 46.38s, Total Time: 4056.01s\n",
      "- Epoch 086 / 120 : Epoch Time: 46.42s, Total Time: 4102.43s\n",
      "- Epoch 087 / 120 : Epoch Time: 46.41s, Total Time: 4148.84s\n",
      "- Epoch 088 / 120 : Epoch Time: 46.55s, Total Time: 4195.39s\n",
      "- Epoch 089 / 120 : Epoch Time: 46.63s, Total Time: 4242.02s\n",
      "- Epoch 090 / 120 : Epoch Time: 46.77s, Total Time: 4288.79s\n",
      "- Epoch 091 / 120 : Epoch Time: 47.71s, Total Time: 4336.49s\n",
      "- Epoch 092 / 120 : Epoch Time: 47.69s, Total Time: 4384.18s\n",
      "- Epoch 093 / 120 : Epoch Time: 46.60s, Total Time: 4430.78s\n",
      "- Epoch 094 / 120 : Epoch Time: 46.59s, Total Time: 4477.37s\n",
      "- Epoch 095 / 120 : Epoch Time: 46.88s, Total Time: 4524.25s\n",
      "- Epoch 096 / 120 : Epoch Time: 46.51s, Total Time: 4570.76s\n",
      "- Epoch 097 / 120 : Epoch Time: 46.51s, Total Time: 4617.27s\n",
      "- Epoch 098 / 120 : Epoch Time: 46.67s, Total Time: 4663.94s\n",
      "- Epoch 099 / 120 : Epoch Time: 46.61s, Total Time: 4710.55s\n",
      "- Epoch 100 / 120 : Epoch Time: 46.74s, Total Time: 4757.29s\n",
      "- Epoch 101 / 120 : Epoch Time: 46.61s, Total Time: 4803.89s\n",
      "- Epoch 102 / 120 : Epoch Time: 46.83s, Total Time: 4850.73s\n",
      "- Epoch 103 / 120 : Epoch Time: 46.65s, Total Time: 4897.38s\n",
      "- Epoch 104 / 120 : Epoch Time: 46.57s, Total Time: 4943.95s\n",
      "- Epoch 105 / 120 : Epoch Time: 47.03s, Total Time: 4990.98s\n",
      "- Epoch 106 / 120 : Epoch Time: 46.72s, Total Time: 5037.70s\n",
      "- Epoch 107 / 120 : Epoch Time: 46.77s, Total Time: 5084.47s\n",
      "- Epoch 108 / 120 : Epoch Time: 46.63s, Total Time: 5131.10s\n",
      "- Epoch 109 / 120 : Epoch Time: 46.57s, Total Time: 5177.67s\n",
      "- Epoch 110 / 120 : Epoch Time: 46.47s, Total Time: 5224.14s\n",
      "- Epoch 111 / 120 : Epoch Time: 46.56s, Total Time: 5270.70s\n",
      "- Epoch 112 / 120 : Epoch Time: 46.77s, Total Time: 5317.47s\n",
      "- Epoch 113 / 120 : Epoch Time: 46.78s, Total Time: 5364.25s\n",
      "- Epoch 114 / 120 : Epoch Time: 46.63s, Total Time: 5410.88s\n",
      "- Epoch 115 / 120 : Epoch Time: 46.58s, Total Time: 5457.47s\n",
      "- Epoch 116 / 120 : Epoch Time: 46.83s, Total Time: 5504.30s\n",
      "- Epoch 117 / 120 : Epoch Time: 47.12s, Total Time: 5551.41s\n",
      "- Epoch 118 / 120 : Epoch Time: 46.77s, Total Time: 5598.18s\n",
      "- Epoch 119 / 120 : Epoch Time: 46.71s, Total Time: 5644.89s\n",
      "- Epoch 120 / 120 : Epoch Time: 46.61s, Total Time: 5691.51s\n",
      "\n",
      "Metrics that each client gets on Test Set by training with Federated Learning Protocol:\n",
      "\n",
      "|    | name     |   accuracy |     loss |   precision |   recall |   roc-auc |\n",
      "|---:|:---------|-----------:|---------:|------------:|---------:|----------:|\n",
      "|  0 | Client 1 |   0.916667 | 0.869939 |    0.924391 | 0.916667 |  0.99493  |\n",
      "|  1 | Client 2 |   0.877778 | 0.853949 |    0.89136  | 0.877778 |  0.994362 |\n",
      "|  2 | Client 3 |   0.911111 | 0.883097 |    0.932214 | 0.911111 |  0.993826 |\n",
      "|  3 | Client 4 |   0.922222 | 0.865542 |    0.928457 | 0.922222 |  0.994946 |\n",
      "|  4 | Client 5 |   0.905556 | 0.861208 |    0.914261 | 0.905556 |  0.994595 |\n"
     ]
    }
   ],
   "source": [
    "simulation_1.run_federated()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269246a8",
   "metadata": {},
   "source": [
    "### Save the Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8eeac836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_save(simulation_1, SAVE_DIR, 'simulation_scenario_1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65892dc2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Scenario 2\n",
    "\n",
    "This scenario uses a MLP Neural Network for classification with the following structure and information:\n",
    "- 64 features.\n",
    "- 10 classes.\n",
    "- 1 hidden layer with 16 neurons and tanh as activation function.\n",
    "- Weights and biases initializated with He initialization method.\n",
    "- Softmax as output layer.\n",
    "\n",
    "The protocol runs over 4 clients and the key length of homomorphic cryptosystem is 1024 bits.\n",
    "\n",
    "The train is executed using 90% of data equally distributed over the 4 clients, with 0.01 as learning rate and 120 epochs.\n",
    "\n",
    "The test is executed using the remaining 10% of data for all clients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf3e9a2",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2e84e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPERPARAMS_2 = {\n",
    "    'n_clients': 4,\n",
    "    'key_length': 1024,\n",
    "    'architecture': {\n",
    "        'n_features': 64, \n",
    "        'n_classes': 10,\n",
    "        'hidden_layers_size': (16,),\n",
    "        'activations': ('tanh',),\n",
    "        'initialization': 'he'\n",
    "    },\n",
    "    'train': {\n",
    "        'learning_rate': 0.01,\n",
    "        'epochs': 120\n",
    "    },\n",
    "    'test': {\n",
    "        'test_size': 0.1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036ce1a0",
   "metadata": {},
   "source": [
    "### Simulation Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "27510a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulaci贸n para 4 clientes\n",
      "\n",
      "        ============================================================================================\n",
      "        Layers size: (64, 16, 10)\n",
      "        ============================================================================================\n",
      "        Activations: ('tanh', 'softmax')\n",
      "        ============================================================================================\n",
      "        Trainable parameters: 1210\n",
      "        ============================================================================================\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "simulation_2 = Simulation(X, y, **HYPERPARAMS_2)\n",
    "print(simulation_2)\n",
    "simulation_2.print_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9357f8c9",
   "metadata": {},
   "source": [
    "### Run on Local Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ce5d5ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running local training for 120 epochs...\n",
      "\n",
      "Metrics that each client gets on Test Set by training only on own local data:\n",
      "\n",
      "|    | name     |   accuracy |    loss |   precision |   recall |   roc-auc |\n",
      "|---:|:---------|-----------:|--------:|------------:|---------:|----------:|\n",
      "|  0 | Client 1 |   0.516667 | 1.75114 |    0.503238 | 0.516667 |  0.86119  |\n",
      "|  1 | Client 2 |   0.494444 | 1.70076 |    0.485757 | 0.494444 |  0.885155 |\n",
      "|  2 | Client 3 |   0.655556 | 1.55343 |    0.674714 | 0.655556 |  0.935602 |\n",
      "|  3 | Client 4 |   0.516667 | 1.6077  |    0.492679 | 0.516667 |  0.914554 |\n"
     ]
    }
   ],
   "source": [
    "simulation_2.run_local()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19755ed5",
   "metadata": {},
   "source": [
    "### Run the Federated Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af6ed5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running distributed gradient aggregation for 120 epochs...\n",
      "\n",
      "- Epoch 001 / 120 : Epoch Time: 74.49s, Total Time: 74.49s\n",
      "- Epoch 002 / 120 : Epoch Time: 73.54s, Total Time: 148.03s\n",
      "- Epoch 003 / 120 : Epoch Time: 71.59s, Total Time: 219.62s\n",
      "- Epoch 004 / 120 : Epoch Time: 74.06s, Total Time: 293.68s\n",
      "- Epoch 005 / 120 : Epoch Time: 77.11s, Total Time: 370.79s\n",
      "- Epoch 006 / 120 : Epoch Time: 77.47s, Total Time: 448.26s\n",
      "- Epoch 007 / 120 : Epoch Time: 75.34s, Total Time: 523.60s\n",
      "- Epoch 008 / 120 : Epoch Time: 76.19s, Total Time: 599.80s\n",
      "- Epoch 009 / 120 : Epoch Time: 75.66s, Total Time: 675.46s\n",
      "- Epoch 010 / 120 : Epoch Time: 76.32s, Total Time: 751.78s\n",
      "- Epoch 011 / 120 : Epoch Time: 79.62s, Total Time: 831.40s\n",
      "- Epoch 012 / 120 : Epoch Time: 76.60s, Total Time: 908.01s\n",
      "- Epoch 013 / 120 : Epoch Time: 76.28s, Total Time: 984.29s\n",
      "- Epoch 014 / 120 : Epoch Time: 79.32s, Total Time: 1063.60s\n",
      "- Epoch 015 / 120 : Epoch Time: 71.78s, Total Time: 1135.38s\n",
      "- Epoch 016 / 120 : Epoch Time: 71.75s, Total Time: 1207.13s\n",
      "- Epoch 017 / 120 : Epoch Time: 71.97s, Total Time: 1279.11s\n",
      "- Epoch 018 / 120 : Epoch Time: 71.94s, Total Time: 1351.04s\n",
      "- Epoch 019 / 120 : Epoch Time: 71.82s, Total Time: 1422.86s\n",
      "- Epoch 020 / 120 : Epoch Time: 72.14s, Total Time: 1495.01s\n",
      "- Epoch 021 / 120 : Epoch Time: 71.93s, Total Time: 1566.94s\n",
      "- Epoch 022 / 120 : Epoch Time: 71.84s, Total Time: 1638.78s\n",
      "- Epoch 023 / 120 : Epoch Time: 71.92s, Total Time: 1710.70s\n",
      "- Epoch 024 / 120 : Epoch Time: 72.05s, Total Time: 1782.75s\n",
      "- Epoch 025 / 120 : Epoch Time: 71.94s, Total Time: 1854.68s\n",
      "- Epoch 026 / 120 : Epoch Time: 72.06s, Total Time: 1926.74s\n",
      "- Epoch 027 / 120 : Epoch Time: 72.19s, Total Time: 1998.93s\n",
      "- Epoch 028 / 120 : Epoch Time: 72.02s, Total Time: 2070.96s\n",
      "- Epoch 029 / 120 : Epoch Time: 72.13s, Total Time: 2143.09s\n",
      "- Epoch 030 / 120 : Epoch Time: 72.22s, Total Time: 2215.31s\n",
      "- Epoch 031 / 120 : Epoch Time: 72.09s, Total Time: 2287.41s\n",
      "- Epoch 032 / 120 : Epoch Time: 72.22s, Total Time: 2359.63s\n",
      "- Epoch 033 / 120 : Epoch Time: 72.49s, Total Time: 2432.12s\n",
      "- Epoch 034 / 120 : Epoch Time: 72.53s, Total Time: 2504.65s\n",
      "- Epoch 035 / 120 : Epoch Time: 72.40s, Total Time: 2577.05s\n",
      "- Epoch 036 / 120 : Epoch Time: 72.47s, Total Time: 2649.52s\n",
      "- Epoch 037 / 120 : Epoch Time: 72.65s, Total Time: 2722.16s\n",
      "- Epoch 038 / 120 : Epoch Time: 72.31s, Total Time: 2794.47s\n",
      "- Epoch 039 / 120 : Epoch Time: 72.46s, Total Time: 2866.94s\n",
      "- Epoch 040 / 120 : Epoch Time: 72.58s, Total Time: 2939.52s\n",
      "- Epoch 041 / 120 : Epoch Time: 72.46s, Total Time: 3011.98s\n",
      "- Epoch 042 / 120 : Epoch Time: 72.26s, Total Time: 3084.24s\n",
      "- Epoch 043 / 120 : Epoch Time: 72.34s, Total Time: 3156.58s\n",
      "- Epoch 044 / 120 : Epoch Time: 72.34s, Total Time: 3228.92s\n",
      "- Epoch 045 / 120 : Epoch Time: 72.60s, Total Time: 3301.52s\n",
      "- Epoch 046 / 120 : Epoch Time: 72.42s, Total Time: 3373.94s\n",
      "- Epoch 047 / 120 : Epoch Time: 72.33s, Total Time: 3446.27s\n",
      "- Epoch 048 / 120 : Epoch Time: 72.32s, Total Time: 3518.59s\n",
      "- Epoch 049 / 120 : Epoch Time: 72.26s, Total Time: 3590.84s\n",
      "- Epoch 050 / 120 : Epoch Time: 72.41s, Total Time: 3663.25s\n",
      "- Epoch 051 / 120 : Epoch Time: 72.34s, Total Time: 3735.59s\n",
      "- Epoch 052 / 120 : Epoch Time: 72.48s, Total Time: 3808.07s\n",
      "- Epoch 053 / 120 : Epoch Time: 72.42s, Total Time: 3880.49s\n",
      "- Epoch 054 / 120 : Epoch Time: 72.30s, Total Time: 3952.79s\n",
      "- Epoch 055 / 120 : Epoch Time: 72.53s, Total Time: 4025.32s\n",
      "- Epoch 056 / 120 : Epoch Time: 72.45s, Total Time: 4097.77s\n",
      "- Epoch 057 / 120 : Epoch Time: 72.37s, Total Time: 4170.14s\n",
      "- Epoch 058 / 120 : Epoch Time: 72.65s, Total Time: 4242.79s\n",
      "- Epoch 059 / 120 : Epoch Time: 72.50s, Total Time: 4315.29s\n",
      "- Epoch 060 / 120 : Epoch Time: 72.29s, Total Time: 4387.58s\n",
      "- Epoch 061 / 120 : Epoch Time: 72.39s, Total Time: 4459.97s\n",
      "- Epoch 062 / 120 : Epoch Time: 72.78s, Total Time: 4532.76s\n",
      "- Epoch 063 / 120 : Epoch Time: 72.43s, Total Time: 4605.19s\n",
      "- Epoch 064 / 120 : Epoch Time: 72.52s, Total Time: 4677.71s\n",
      "- Epoch 065 / 120 : Epoch Time: 72.60s, Total Time: 4750.31s\n",
      "- Epoch 066 / 120 : Epoch Time: 72.70s, Total Time: 4823.01s\n",
      "- Epoch 067 / 120 : Epoch Time: 72.52s, Total Time: 4895.53s\n",
      "- Epoch 068 / 120 : Epoch Time: 72.72s, Total Time: 4968.25s\n",
      "- Epoch 069 / 120 : Epoch Time: 72.32s, Total Time: 5040.57s\n",
      "- Epoch 070 / 120 : Epoch Time: 72.84s, Total Time: 5113.40s\n",
      "- Epoch 071 / 120 : Epoch Time: 72.65s, Total Time: 5186.05s\n",
      "- Epoch 072 / 120 : Epoch Time: 72.33s, Total Time: 5258.38s\n",
      "- Epoch 073 / 120 : Epoch Time: 72.78s, Total Time: 5331.16s\n",
      "- Epoch 074 / 120 : Epoch Time: 72.35s, Total Time: 5403.51s\n",
      "- Epoch 075 / 120 : Epoch Time: 72.12s, Total Time: 5475.63s\n",
      "- Epoch 076 / 120 : Epoch Time: 72.17s, Total Time: 5547.80s\n",
      "- Epoch 077 / 120 : Epoch Time: 72.13s, Total Time: 5619.93s\n",
      "- Epoch 078 / 120 : Epoch Time: 72.38s, Total Time: 5692.31s\n",
      "- Epoch 079 / 120 : Epoch Time: 72.56s, Total Time: 5764.87s\n",
      "- Epoch 080 / 120 : Epoch Time: 72.47s, Total Time: 5837.34s\n",
      "- Epoch 081 / 120 : Epoch Time: 72.34s, Total Time: 5909.67s\n",
      "- Epoch 082 / 120 : Epoch Time: 72.28s, Total Time: 5981.96s\n",
      "- Epoch 083 / 120 : Epoch Time: 72.30s, Total Time: 6054.26s\n",
      "- Epoch 084 / 120 : Epoch Time: 72.50s, Total Time: 6126.76s\n",
      "- Epoch 085 / 120 : Epoch Time: 72.17s, Total Time: 6198.93s\n",
      "- Epoch 086 / 120 : Epoch Time: 72.36s, Total Time: 6271.29s\n",
      "- Epoch 087 / 120 : Epoch Time: 72.29s, Total Time: 6343.58s\n",
      "- Epoch 088 / 120 : Epoch Time: 72.32s, Total Time: 6415.91s\n",
      "- Epoch 089 / 120 : Epoch Time: 72.36s, Total Time: 6488.26s\n",
      "- Epoch 090 / 120 : Epoch Time: 72.49s, Total Time: 6560.76s\n",
      "- Epoch 091 / 120 : Epoch Time: 72.28s, Total Time: 6633.03s\n",
      "- Epoch 092 / 120 : Epoch Time: 72.40s, Total Time: 6705.43s\n",
      "- Epoch 093 / 120 : Epoch Time: 72.48s, Total Time: 6777.91s\n",
      "- Epoch 094 / 120 : Epoch Time: 72.34s, Total Time: 6850.25s\n",
      "- Epoch 095 / 120 : Epoch Time: 72.57s, Total Time: 6922.83s\n",
      "- Epoch 096 / 120 : Epoch Time: 72.37s, Total Time: 6995.20s\n",
      "- Epoch 097 / 120 : Epoch Time: 72.42s, Total Time: 7067.61s\n",
      "- Epoch 098 / 120 : Epoch Time: 72.18s, Total Time: 7139.80s\n",
      "- Epoch 099 / 120 : Epoch Time: 72.02s, Total Time: 7211.82s\n",
      "- Epoch 100 / 120 : Epoch Time: 72.14s, Total Time: 7283.96s\n",
      "- Epoch 101 / 120 : Epoch Time: 72.23s, Total Time: 7356.19s\n",
      "- Epoch 102 / 120 : Epoch Time: 72.49s, Total Time: 7428.67s\n",
      "- Epoch 103 / 120 : Epoch Time: 72.20s, Total Time: 7500.87s\n",
      "- Epoch 104 / 120 : Epoch Time: 72.11s, Total Time: 7572.98s\n",
      "- Epoch 105 / 120 : Epoch Time: 73.29s, Total Time: 7646.27s\n",
      "- Epoch 106 / 120 : Epoch Time: 72.16s, Total Time: 7718.43s\n",
      "- Epoch 107 / 120 : Epoch Time: 72.45s, Total Time: 7790.87s\n",
      "- Epoch 108 / 120 : Epoch Time: 72.68s, Total Time: 7863.55s\n",
      "- Epoch 109 / 120 : Epoch Time: 72.57s, Total Time: 7936.12s\n",
      "- Epoch 110 / 120 : Epoch Time: 72.56s, Total Time: 8008.69s\n",
      "- Epoch 111 / 120 : Epoch Time: 72.82s, Total Time: 8081.51s\n",
      "- Epoch 112 / 120 : Epoch Time: 72.79s, Total Time: 8154.30s\n",
      "- Epoch 113 / 120 : Epoch Time: 72.35s, Total Time: 8226.65s\n",
      "- Epoch 114 / 120 : Epoch Time: 72.34s, Total Time: 8298.99s\n",
      "- Epoch 115 / 120 : Epoch Time: 72.33s, Total Time: 8371.31s\n",
      "- Epoch 116 / 120 : Epoch Time: 72.30s, Total Time: 8443.62s\n",
      "- Epoch 117 / 120 : Epoch Time: 72.35s, Total Time: 8515.96s\n",
      "- Epoch 118 / 120 : Epoch Time: 72.33s, Total Time: 8588.29s\n",
      "- Epoch 119 / 120 : Epoch Time: 72.66s, Total Time: 8660.95s\n",
      "- Epoch 120 / 120 : Epoch Time: 72.54s, Total Time: 8733.48s\n",
      "\n",
      "Metrics that each client gets on Test Set by training with Federated Learning Protocol:\n",
      "\n",
      "|    | name     |   accuracy |    loss |   precision |   recall |   roc-auc |\n",
      "|---:|:---------|-----------:|--------:|------------:|---------:|----------:|\n",
      "|  0 | Client 1 |   0.616667 | 1.62678 |    0.604753 | 0.616667 |  0.89628  |\n",
      "|  1 | Client 2 |   0.505556 | 1.69871 |    0.499156 | 0.505556 |  0.884563 |\n",
      "|  2 | Client 3 |   0.616667 | 1.55482 |    0.633297 | 0.616667 |  0.93282  |\n",
      "|  3 | Client 4 |   0.588889 | 1.49307 |    0.536639 | 0.588889 |  0.935412 |\n"
     ]
    }
   ],
   "source": [
    "simulation_2.run_federated()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f199f0a",
   "metadata": {},
   "source": [
    "### Save the Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "80d5fd36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_save(simulation_2, SAVE_DIR, 'simulation_scenario_2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3a2405",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Scenario 3\n",
    "\n",
    "This scenario uses a MLP Neural Network for classification with the following structure and information:\n",
    "- 64 features.\n",
    "- 10 classes.\n",
    "- 2 hidden layers with 32 and 16 neurons respectively and tanh as activation function.\n",
    "- Weights and biases initializated with He initialization method.\n",
    "- Softmax as output layer.\n",
    "\n",
    "The protocol runs over 3 clients and the key length of homomorphic cryptosystem is 1024 bits.\n",
    "\n",
    "The train is executed using 90% of data equally distributed over the 3 clients, with 0.01 as learning rate and 120 epochs.\n",
    "\n",
    "The test is executed using the remaining 10% of data for all clients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90522e9e",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5ef7ea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPERPARAMS_3 = {\n",
    "    'n_clients': 3,\n",
    "    'key_length': 1024,\n",
    "    'architecture': {\n",
    "        'n_features': 64, \n",
    "        'n_classes': 10,\n",
    "        'hidden_layers_size': (32,16),\n",
    "        'activations': ('tanh','tanh'),\n",
    "        'initialization': 'he'\n",
    "    },\n",
    "    'train': {\n",
    "        'learning_rate': 0.01,\n",
    "        'epochs': 120\n",
    "    },\n",
    "    'test': {\n",
    "        'test_size': 0.1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa06cbb6",
   "metadata": {},
   "source": [
    "### Simulation Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0d6082df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulaci贸n para 3 clientes\n",
      "\n",
      "        ============================================================================================\n",
      "        Layers size: (64, 32, 16, 10)\n",
      "        ============================================================================================\n",
      "        Activations: ('tanh', 'tanh', 'softmax')\n",
      "        ============================================================================================\n",
      "        Trainable parameters: 2778\n",
      "        ============================================================================================\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "simulation_3 = Simulation(X, y, **HYPERPARAMS_3)\n",
    "print(simulation_3)\n",
    "simulation_3.print_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d65f81",
   "metadata": {},
   "source": [
    "### Run on Local Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9ca169f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running local training for 120 epochs...\n",
      "\n",
      "Metrics that each client gets on Test Set by training only on own local data:\n",
      "\n",
      "|    | name     |   accuracy |    loss |   precision |   recall |   roc-auc |\n",
      "|---:|:---------|-----------:|--------:|------------:|---------:|----------:|\n",
      "|  0 | Client 1 |   0.494444 | 1.65769 |    0.495888 | 0.494444 |  0.896748 |\n",
      "|  1 | Client 2 |   0.588889 | 1.7016  |    0.650985 | 0.588889 |  0.886472 |\n",
      "|  2 | Client 3 |   0.538889 | 1.70539 |    0.520901 | 0.538889 |  0.86582  |\n"
     ]
    }
   ],
   "source": [
    "simulation_3.run_local()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4460a354",
   "metadata": {},
   "source": [
    "### Run the Federated Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "87e474ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running distributed gradient aggregation for 120 epochs...\n",
      "\n",
      "- Epoch 001 / 120 : Epoch Time: 125.95s, Total Time: 125.95s\n",
      "- Epoch 002 / 120 : Epoch Time: 126.61s, Total Time: 252.56s\n",
      "- Epoch 003 / 120 : Epoch Time: 127.00s, Total Time: 379.55s\n",
      "- Epoch 004 / 120 : Epoch Time: 126.94s, Total Time: 506.49s\n",
      "- Epoch 005 / 120 : Epoch Time: 126.91s, Total Time: 633.40s\n",
      "- Epoch 006 / 120 : Epoch Time: 128.13s, Total Time: 761.54s\n",
      "- Epoch 007 / 120 : Epoch Time: 132.93s, Total Time: 894.47s\n",
      "- Epoch 008 / 120 : Epoch Time: 127.32s, Total Time: 1021.79s\n",
      "- Epoch 009 / 120 : Epoch Time: 126.91s, Total Time: 1148.70s\n",
      "- Epoch 010 / 120 : Epoch Time: 127.11s, Total Time: 1275.81s\n",
      "- Epoch 011 / 120 : Epoch Time: 127.03s, Total Time: 1402.84s\n",
      "- Epoch 012 / 120 : Epoch Time: 127.59s, Total Time: 1530.43s\n",
      "- Epoch 013 / 120 : Epoch Time: 126.88s, Total Time: 1657.31s\n",
      "- Epoch 014 / 120 : Epoch Time: 127.45s, Total Time: 1784.75s\n",
      "- Epoch 015 / 120 : Epoch Time: 127.77s, Total Time: 1912.52s\n",
      "- Epoch 016 / 120 : Epoch Time: 127.73s, Total Time: 2040.25s\n",
      "- Epoch 017 / 120 : Epoch Time: 127.92s, Total Time: 2168.18s\n",
      "- Epoch 018 / 120 : Epoch Time: 127.82s, Total Time: 2295.99s\n",
      "- Epoch 019 / 120 : Epoch Time: 128.36s, Total Time: 2424.35s\n",
      "- Epoch 020 / 120 : Epoch Time: 128.12s, Total Time: 2552.47s\n",
      "- Epoch 021 / 120 : Epoch Time: 127.96s, Total Time: 2680.42s\n",
      "- Epoch 022 / 120 : Epoch Time: 127.38s, Total Time: 2807.80s\n",
      "- Epoch 023 / 120 : Epoch Time: 127.57s, Total Time: 2935.36s\n",
      "- Epoch 024 / 120 : Epoch Time: 127.71s, Total Time: 3063.08s\n",
      "- Epoch 025 / 120 : Epoch Time: 127.67s, Total Time: 3190.74s\n",
      "- Epoch 026 / 120 : Epoch Time: 127.98s, Total Time: 3318.73s\n",
      "- Epoch 027 / 120 : Epoch Time: 127.93s, Total Time: 3446.66s\n",
      "- Epoch 028 / 120 : Epoch Time: 127.78s, Total Time: 3574.43s\n",
      "- Epoch 029 / 120 : Epoch Time: 127.68s, Total Time: 3702.11s\n",
      "- Epoch 030 / 120 : Epoch Time: 128.01s, Total Time: 3830.12s\n",
      "- Epoch 031 / 120 : Epoch Time: 127.86s, Total Time: 3957.98s\n",
      "- Epoch 032 / 120 : Epoch Time: 127.81s, Total Time: 4085.80s\n",
      "- Epoch 033 / 120 : Epoch Time: 127.70s, Total Time: 4213.50s\n",
      "- Epoch 034 / 120 : Epoch Time: 128.00s, Total Time: 4341.50s\n",
      "- Epoch 035 / 120 : Epoch Time: 128.01s, Total Time: 4469.51s\n",
      "- Epoch 036 / 120 : Epoch Time: 127.87s, Total Time: 4597.38s\n",
      "- Epoch 037 / 120 : Epoch Time: 128.35s, Total Time: 4725.73s\n",
      "- Epoch 038 / 120 : Epoch Time: 127.94s, Total Time: 4853.68s\n",
      "- Epoch 039 / 120 : Epoch Time: 127.61s, Total Time: 4981.29s\n",
      "- Epoch 040 / 120 : Epoch Time: 127.92s, Total Time: 5109.20s\n",
      "- Epoch 041 / 120 : Epoch Time: 127.94s, Total Time: 5237.14s\n",
      "- Epoch 042 / 120 : Epoch Time: 128.32s, Total Time: 5365.46s\n",
      "- Epoch 043 / 120 : Epoch Time: 127.73s, Total Time: 5493.19s\n",
      "- Epoch 044 / 120 : Epoch Time: 127.72s, Total Time: 5620.92s\n",
      "- Epoch 045 / 120 : Epoch Time: 128.09s, Total Time: 5749.01s\n",
      "- Epoch 046 / 120 : Epoch Time: 127.76s, Total Time: 5876.77s\n",
      "- Epoch 047 / 120 : Epoch Time: 127.97s, Total Time: 6004.74s\n",
      "- Epoch 048 / 120 : Epoch Time: 127.76s, Total Time: 6132.50s\n",
      "- Epoch 049 / 120 : Epoch Time: 128.14s, Total Time: 6260.64s\n",
      "- Epoch 050 / 120 : Epoch Time: 127.86s, Total Time: 6388.50s\n",
      "- Epoch 051 / 120 : Epoch Time: 127.83s, Total Time: 6516.32s\n",
      "- Epoch 052 / 120 : Epoch Time: 127.82s, Total Time: 6644.14s\n",
      "- Epoch 053 / 120 : Epoch Time: 127.98s, Total Time: 6772.12s\n",
      "- Epoch 054 / 120 : Epoch Time: 128.07s, Total Time: 6900.19s\n",
      "- Epoch 055 / 120 : Epoch Time: 127.59s, Total Time: 7027.79s\n",
      "- Epoch 056 / 120 : Epoch Time: 128.07s, Total Time: 7155.86s\n",
      "- Epoch 057 / 120 : Epoch Time: 128.08s, Total Time: 7283.94s\n",
      "- Epoch 058 / 120 : Epoch Time: 127.79s, Total Time: 7411.73s\n",
      "- Epoch 059 / 120 : Epoch Time: 127.34s, Total Time: 7539.07s\n",
      "- Epoch 060 / 120 : Epoch Time: 127.29s, Total Time: 7666.36s\n",
      "- Epoch 061 / 120 : Epoch Time: 127.43s, Total Time: 7793.79s\n",
      "- Epoch 062 / 120 : Epoch Time: 127.75s, Total Time: 7921.53s\n",
      "- Epoch 063 / 120 : Epoch Time: 127.66s, Total Time: 8049.19s\n",
      "- Epoch 064 / 120 : Epoch Time: 128.00s, Total Time: 8177.19s\n",
      "- Epoch 065 / 120 : Epoch Time: 128.02s, Total Time: 8305.21s\n",
      "- Epoch 066 / 120 : Epoch Time: 127.58s, Total Time: 8432.79s\n",
      "- Epoch 067 / 120 : Epoch Time: 127.77s, Total Time: 8560.56s\n",
      "- Epoch 068 / 120 : Epoch Time: 128.12s, Total Time: 8688.68s\n",
      "- Epoch 069 / 120 : Epoch Time: 127.39s, Total Time: 8816.07s\n",
      "- Epoch 070 / 120 : Epoch Time: 126.35s, Total Time: 8942.42s\n",
      "- Epoch 071 / 120 : Epoch Time: 126.13s, Total Time: 9068.55s\n",
      "- Epoch 072 / 120 : Epoch Time: 126.31s, Total Time: 9194.86s\n",
      "- Epoch 073 / 120 : Epoch Time: 126.43s, Total Time: 9321.29s\n",
      "- Epoch 074 / 120 : Epoch Time: 126.42s, Total Time: 9447.70s\n",
      "- Epoch 075 / 120 : Epoch Time: 125.69s, Total Time: 9573.39s\n",
      "- Epoch 076 / 120 : Epoch Time: 126.41s, Total Time: 9699.81s\n",
      "- Epoch 077 / 120 : Epoch Time: 126.53s, Total Time: 9826.34s\n",
      "- Epoch 078 / 120 : Epoch Time: 126.10s, Total Time: 9952.44s\n",
      "- Epoch 079 / 120 : Epoch Time: 126.11s, Total Time: 10078.55s\n",
      "- Epoch 080 / 120 : Epoch Time: 126.19s, Total Time: 10204.74s\n",
      "- Epoch 081 / 120 : Epoch Time: 126.35s, Total Time: 10331.09s\n",
      "- Epoch 082 / 120 : Epoch Time: 126.71s, Total Time: 10457.80s\n",
      "- Epoch 083 / 120 : Epoch Time: 126.41s, Total Time: 10584.21s\n",
      "- Epoch 084 / 120 : Epoch Time: 126.28s, Total Time: 10710.49s\n",
      "- Epoch 085 / 120 : Epoch Time: 126.21s, Total Time: 10836.70s\n",
      "- Epoch 086 / 120 : Epoch Time: 126.32s, Total Time: 10963.02s\n",
      "- Epoch 087 / 120 : Epoch Time: 126.78s, Total Time: 11089.79s\n",
      "- Epoch 088 / 120 : Epoch Time: 126.27s, Total Time: 11216.07s\n",
      "- Epoch 089 / 120 : Epoch Time: 126.34s, Total Time: 11342.40s\n",
      "- Epoch 090 / 120 : Epoch Time: 126.63s, Total Time: 11469.03s\n",
      "- Epoch 091 / 120 : Epoch Time: 126.49s, Total Time: 11595.53s\n",
      "- Epoch 092 / 120 : Epoch Time: 126.38s, Total Time: 11721.91s\n",
      "- Epoch 093 / 120 : Epoch Time: 126.08s, Total Time: 11847.99s\n",
      "- Epoch 094 / 120 : Epoch Time: 126.26s, Total Time: 11974.25s\n",
      "- Epoch 095 / 120 : Epoch Time: 126.45s, Total Time: 12100.70s\n",
      "- Epoch 096 / 120 : Epoch Time: 126.41s, Total Time: 12227.11s\n",
      "- Epoch 097 / 120 : Epoch Time: 126.55s, Total Time: 12353.66s\n",
      "- Epoch 098 / 120 : Epoch Time: 126.47s, Total Time: 12480.13s\n",
      "- Epoch 099 / 120 : Epoch Time: 126.40s, Total Time: 12606.53s\n",
      "- Epoch 100 / 120 : Epoch Time: 126.18s, Total Time: 12732.71s\n",
      "- Epoch 101 / 120 : Epoch Time: 126.64s, Total Time: 12859.35s\n",
      "- Epoch 102 / 120 : Epoch Time: 126.36s, Total Time: 12985.71s\n",
      "- Epoch 103 / 120 : Epoch Time: 126.42s, Total Time: 13112.13s\n",
      "- Epoch 104 / 120 : Epoch Time: 126.46s, Total Time: 13238.59s\n",
      "- Epoch 105 / 120 : Epoch Time: 126.38s, Total Time: 13364.97s\n",
      "- Epoch 106 / 120 : Epoch Time: 126.61s, Total Time: 13491.58s\n",
      "- Epoch 107 / 120 : Epoch Time: 126.41s, Total Time: 13617.98s\n",
      "- Epoch 108 / 120 : Epoch Time: 126.31s, Total Time: 13744.29s\n",
      "- Epoch 109 / 120 : Epoch Time: 126.46s, Total Time: 13870.75s\n",
      "- Epoch 110 / 120 : Epoch Time: 126.52s, Total Time: 13997.27s\n",
      "- Epoch 111 / 120 : Epoch Time: 126.86s, Total Time: 14124.13s\n",
      "- Epoch 112 / 120 : Epoch Time: 126.59s, Total Time: 14250.72s\n",
      "- Epoch 113 / 120 : Epoch Time: 126.48s, Total Time: 14377.20s\n",
      "- Epoch 114 / 120 : Epoch Time: 126.75s, Total Time: 14503.95s\n",
      "- Epoch 115 / 120 : Epoch Time: 126.61s, Total Time: 14630.56s\n",
      "- Epoch 116 / 120 : Epoch Time: 126.66s, Total Time: 14757.22s\n",
      "- Epoch 117 / 120 : Epoch Time: 126.29s, Total Time: 14883.51s\n",
      "- Epoch 118 / 120 : Epoch Time: 126.60s, Total Time: 15010.11s\n",
      "- Epoch 119 / 120 : Epoch Time: 126.38s, Total Time: 15136.49s\n",
      "- Epoch 120 / 120 : Epoch Time: 126.36s, Total Time: 15262.86s\n",
      "\n",
      "Metrics that each client gets on Test Set by training with Federated Learning Protocol:\n",
      "\n",
      "|    | name     |   accuracy |    loss |   precision |   recall |   roc-auc |\n",
      "|---:|:---------|-----------:|--------:|------------:|---------:|----------:|\n",
      "|  0 | Client 1 |   0.588889 | 1.53589 |    0.634221 | 0.588889 |  0.91974  |\n",
      "|  1 | Client 2 |   0.572222 | 1.72781 |    0.621535 | 0.572222 |  0.876926 |\n",
      "|  2 | Client 3 |   0.588889 | 1.57979 |    0.560777 | 0.588889 |  0.892035 |\n"
     ]
    }
   ],
   "source": [
    "simulation_3.run_federated()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a2b7c3",
   "metadata": {},
   "source": [
    "### Save the Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "990d7587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_save(simulation_3, SAVE_DIR, 'simulation_scenario_3.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551e0745",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Load Simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddc7e3d",
   "metadata": {},
   "source": [
    "### Scenario 1\n",
    "\n",
    "This scenario uses a MLP Neural Network for classification with the following structure and information:\n",
    "- 64 features.\n",
    "- 10 classes.\n",
    "- No hidden layers.\n",
    "- Weights and biases initializated in zeros.\n",
    "- Softmax as output layer.\n",
    "\n",
    "The protocol runs over 5 clients and the key length of homomorphic cryptosystem is 1024 bits.\n",
    "\n",
    "The train is executed using 90% of data equally distributed over the 5 clients, with 0.01 as learning rate and 120 epochs.\n",
    "\n",
    "The test is executed using the remaining 10% of data for all clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dbe71d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1 = pickle_load(SAVE_DIR, 'simulation_scenario_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2df5a29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulaci贸n para 5 clientes\n",
      "\n",
      "        ============================================================================================\n",
      "        Layers size: (64, 10)\n",
      "        ============================================================================================\n",
      "        Activations: ('softmax',)\n",
      "        ============================================================================================\n",
      "        Trainable parameters: 650\n",
      "        ============================================================================================\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(scenario_1)\n",
    "scenario_1.print_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6362cad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics that each client gets on Test Set by training only on own local data:\n",
      "\n",
      "|    | name     |   accuracy |    loss |   precision |   recall |   roc-auc |\n",
      "|---:|:---------|-----------:|--------:|------------:|---------:|----------:|\n",
      "|  0 | Client 1 |   0.916667 | 1.05915 |    0.926553 | 0.916667 |  0.993473 |\n",
      "|  1 | Client 2 |   0.872222 | 1.03494 |    0.887286 | 0.872222 |  0.992943 |\n",
      "|  2 | Client 3 |   0.883333 | 1.07236 |    0.914019 | 0.883333 |  0.992837 |\n",
      "|  3 | Client 4 |   0.9      | 1.05519 |    0.904683 | 0.9      |  0.992879 |\n",
      "|  4 | Client 5 |   0.9      | 1.04635 |    0.91044  | 0.9      |  0.993189 |\n"
     ]
    }
   ],
   "source": [
    "scenario_1.print_local_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b88f9e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics that each client gets on Test Set by training with Federated Learning Protocol:\n",
      "\n",
      "|    | name     |   accuracy |     loss |   precision |   recall |   roc-auc |\n",
      "|---:|:---------|-----------:|---------:|------------:|---------:|----------:|\n",
      "|  0 | Client 1 |   0.916667 | 0.869939 |    0.924391 | 0.916667 |  0.99493  |\n",
      "|  1 | Client 2 |   0.877778 | 0.853949 |    0.89136  | 0.877778 |  0.994362 |\n",
      "|  2 | Client 3 |   0.911111 | 0.883097 |    0.932214 | 0.911111 |  0.993826 |\n",
      "|  3 | Client 4 |   0.922222 | 0.865542 |    0.928457 | 0.922222 |  0.994946 |\n",
      "|  4 | Client 5 |   0.905556 | 0.861208 |    0.914261 | 0.905556 |  0.994595 |\n"
     ]
    }
   ],
   "source": [
    "scenario_1.print_federated_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbc1e7e",
   "metadata": {},
   "source": [
    "### Scenario 2\n",
    "\n",
    "This scenario uses a MLP Neural Network for classification with the following structure and information:\n",
    "- 64 features.\n",
    "- 10 classes.\n",
    "- 1 hidden layer with 16 neurons and tanh as activation function.\n",
    "- Weights and biases initializated with He initialization method.\n",
    "- Softmax as output layer.\n",
    "\n",
    "The protocol runs over 4 clients and the key length of homomorphic cryptosystem is 1024 bits.\n",
    "\n",
    "The train is executed using 90% of data equally distributed over the 4 clients, with 0.01 as learning rate and 120 epochs.\n",
    "\n",
    "The test is executed using the remaining 10% of data for all clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e7da4ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_2 = pickle_load(SAVE_DIR, 'simulation_scenario_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f496a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulaci贸n para 4 clientes\n",
      "\n",
      "        ============================================================================================\n",
      "        Layers size: (64, 16, 10)\n",
      "        ============================================================================================\n",
      "        Activations: ('tanh', 'softmax')\n",
      "        ============================================================================================\n",
      "        Trainable parameters: 1210\n",
      "        ============================================================================================\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(scenario_2)\n",
    "scenario_2.print_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "82822697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics that each client gets on Test Set by training only on own local data:\n",
      "\n",
      "|    | name     |   accuracy |    loss |   precision |   recall |   roc-auc |\n",
      "|---:|:---------|-----------:|--------:|------------:|---------:|----------:|\n",
      "|  0 | Client 1 |   0.516667 | 1.75114 |    0.503238 | 0.516667 |  0.86119  |\n",
      "|  1 | Client 2 |   0.494444 | 1.70076 |    0.485757 | 0.494444 |  0.885155 |\n",
      "|  2 | Client 3 |   0.655556 | 1.55343 |    0.674714 | 0.655556 |  0.935602 |\n",
      "|  3 | Client 4 |   0.516667 | 1.6077  |    0.492679 | 0.516667 |  0.914554 |\n"
     ]
    }
   ],
   "source": [
    "scenario_2.print_local_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6e00fc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics that each client gets on Test Set by training with Federated Learning Protocol:\n",
      "\n",
      "|    | name     |   accuracy |    loss |   precision |   recall |   roc-auc |\n",
      "|---:|:---------|-----------:|--------:|------------:|---------:|----------:|\n",
      "|  0 | Client 1 |   0.616667 | 1.62678 |    0.604753 | 0.616667 |  0.89628  |\n",
      "|  1 | Client 2 |   0.505556 | 1.69871 |    0.499156 | 0.505556 |  0.884563 |\n",
      "|  2 | Client 3 |   0.616667 | 1.55482 |    0.633297 | 0.616667 |  0.93282  |\n",
      "|  3 | Client 4 |   0.588889 | 1.49307 |    0.536639 | 0.588889 |  0.935412 |\n"
     ]
    }
   ],
   "source": [
    "scenario_2.print_federated_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d596c81a",
   "metadata": {},
   "source": [
    "### Scenario 3\n",
    "\n",
    "This scenario uses a MLP Neural Network for classification with the following structure and information:\n",
    "- 64 features.\n",
    "- 10 classes.\n",
    "- 2 hidden layers with 32 and 16 neurons respectively and tanh as activation function.\n",
    "- Weights and biases initializated with He initialization method.\n",
    "- Softmax as output layer.\n",
    "\n",
    "The protocol runs over 3 clients and the key length of homomorphic cryptosystem is 1024 bits.\n",
    "\n",
    "The train is executed using 90% of data equally distributed over the 3 clients, with 0.01 as learning rate and 120 epochs.\n",
    "\n",
    "The test is executed using the remaining 10% of data for all clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f665b104",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_3 = pickle_load(SAVE_DIR, 'simulation_scenario_3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a3a3d5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulaci贸n para 3 clientes\n",
      "\n",
      "        ============================================================================================\n",
      "        Layers size: (64, 32, 16, 10)\n",
      "        ============================================================================================\n",
      "        Activations: ('tanh', 'tanh', 'softmax')\n",
      "        ============================================================================================\n",
      "        Trainable parameters: 2778\n",
      "        ============================================================================================\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(scenario_3)\n",
    "scenario_3.print_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2642fb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics that each client gets on Test Set by training only on own local data:\n",
      "\n",
      "|    | name     |   accuracy |    loss |   precision |   recall |   roc-auc |\n",
      "|---:|:---------|-----------:|--------:|------------:|---------:|----------:|\n",
      "|  0 | Client 1 |   0.494444 | 1.65769 |    0.495888 | 0.494444 |  0.896748 |\n",
      "|  1 | Client 2 |   0.588889 | 1.7016  |    0.650985 | 0.588889 |  0.886472 |\n",
      "|  2 | Client 3 |   0.538889 | 1.70539 |    0.520901 | 0.538889 |  0.86582  |\n"
     ]
    }
   ],
   "source": [
    "scenario_3.print_local_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "30000402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics that each client gets on Test Set by training with Federated Learning Protocol:\n",
      "\n",
      "|    | name     |   accuracy |    loss |   precision |   recall |   roc-auc |\n",
      "|---:|:---------|-----------:|--------:|------------:|---------:|----------:|\n",
      "|  0 | Client 1 |   0.588889 | 1.53589 |    0.634221 | 0.588889 |  0.91974  |\n",
      "|  1 | Client 2 |   0.572222 | 1.72781 |    0.621535 | 0.572222 |  0.876926 |\n",
      "|  2 | Client 3 |   0.588889 | 1.57979 |    0.560777 | 0.588889 |  0.892035 |\n"
     ]
    }
   ],
   "source": [
    "scenario_3.print_federated_metrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
